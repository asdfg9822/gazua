{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "5                 2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.tsv\", sep=\"\\t\", index_col=\"PhraseId\")\n",
    "\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase\n",
       "PhraseId                                                               \n",
       "156061          8545  An intermittently pleasing but mostly routine ...\n",
       "156062          8545  An intermittently pleasing but mostly routine ...\n",
       "156063          8545                                                 An\n",
       "156064          8545  intermittently pleasing but mostly routine effort\n",
       "156065          8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test.tsv\", sep=\"\\t\", index_col=\"PhraseId\")\n",
    "\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>series</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "1         A series of escapades demonstrating the adage ...   \n",
       "2         A series of escapades demonstrating the adage ...   \n",
       "3                                                  A series   \n",
       "4                                                         A   \n",
       "5                                                    series   \n",
       "\n",
       "                                             Phrase(origin)  \n",
       "PhraseId                                                     \n",
       "1         A series of escapades demonstrating the adage ...  \n",
       "2         A series of escapades demonstrating the adage ...  \n",
       "3                                                  A series  \n",
       "4                                                         A  \n",
       "5                                                    series  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Phrase(origin)\"] = train[\"Phrase\"].copy()\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>An</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "156061    An intermittently pleasing but mostly routine ...   \n",
       "156062    An intermittently pleasing but mostly routine ...   \n",
       "156063                                                   An   \n",
       "156064    intermittently pleasing but mostly routine effort   \n",
       "156065           intermittently pleasing but mostly routine   \n",
       "\n",
       "                                             Phrase(origin)  \n",
       "PhraseId                                                     \n",
       "156061    An intermittently pleasing but mostly routine ...  \n",
       "156062    An intermittently pleasing but mostly routine ...  \n",
       "156063                                                   An  \n",
       "156064    intermittently pleasing but mostly routine effort  \n",
       "156065           intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Phrase(origin)\"] = test[\"Phrase\"].copy()\n",
    "\n",
    "print(test.shape)\n",
    "test[[\"Phrase\", \"Phrase(origin)\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>series</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "1         A series of escapades demonstrating the adage ...   \n",
       "2         A series of escapades demonstrating the adage ...   \n",
       "3                                                  A series   \n",
       "4                                                         A   \n",
       "5                                                    series   \n",
       "\n",
       "                                             Phrase(origin)  \n",
       "PhraseId                                                     \n",
       "1         A series of escapades demonstrating the adage ...  \n",
       "2         A series of escapades demonstrating the adage ...  \n",
       "3                                                  A series  \n",
       "4                                                         A  \n",
       "5                                                    series  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(phrase):\n",
    "    phrase = phrase.replace(\"doesn't \", \"does not \")\n",
    "    phrase = phrase.replace(\"ca n't \", \"can not \")\n",
    "    phrase = phrase.replace(\" n't \", \" not \")\n",
    "    phrase = re.sub(r\"[0-9]\",\"\",phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "train[\"Phrase\"] = train[\"Phrase\"].apply(clean_text)\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>An</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "156061    An intermittently pleasing but mostly routine ...   \n",
       "156062    An intermittently pleasing but mostly routine ...   \n",
       "156063                                                   An   \n",
       "156064    intermittently pleasing but mostly routine effort   \n",
       "156065           intermittently pleasing but mostly routine   \n",
       "\n",
       "                                             Phrase(origin)  \n",
       "PhraseId                                                     \n",
       "156061    An intermittently pleasing but mostly routine ...  \n",
       "156062    An intermittently pleasing but mostly routine ...  \n",
       "156063                                                   An  \n",
       "156064    intermittently pleasing but mostly routine effort  \n",
       "156065           intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Phrase\"] = test[\"Phrase\"].apply(clean_text)\n",
    "\n",
    "print(test.shape)\n",
    "test[[\"Phrase\", \"Phrase(origin)\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stemming...: 100%|██████████| 156060/156060 [00:24<00:00, 6326.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>series</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "1         A series of escapades demonstrating the adage ...   \n",
       "2         A series of escapades demonstrating the adage ...   \n",
       "3                                                  A series   \n",
       "4                                                         A   \n",
       "5                                                    series   \n",
       "\n",
       "                                             Phrase(origin)  \n",
       "PhraseId                                                     \n",
       "1         A series of escapades demonstrating the adage ...  \n",
       "2         A series of escapades demonstrating the adage ...  \n",
       "3                                                  A series  \n",
       "4                                                         A  \n",
       "5                                                    series  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def stem_phrase(phrase1):\n",
    "    stemmed_words = [stemmer.stem(w) for w in phrase1.split(\" \")]\n",
    "    stemmed_phrase = \" \".join(stemmed_words)\n",
    "\n",
    "    return stemmed_phrase\n",
    "\n",
    "tqdm.pandas(desc=\"Stemming...\")\n",
    "train[\"Phrase\"].progress_apply(stem_phrase).head()\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stemming...: 100%|██████████| 66292/66292 [00:09<00:00, 7282.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>An</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "156061    An intermittently pleasing but mostly routine ...   \n",
       "156062    An intermittently pleasing but mostly routine ...   \n",
       "156063                                                   An   \n",
       "156064    intermittently pleasing but mostly routine effort   \n",
       "156065           intermittently pleasing but mostly routine   \n",
       "\n",
       "                                             Phrase(origin)  \n",
       "PhraseId                                                     \n",
       "156061    An intermittently pleasing but mostly routine ...  \n",
       "156062    An intermittently pleasing but mostly routine ...  \n",
       "156063                                                   An  \n",
       "156064    intermittently pleasing but mostly routine effort  \n",
       "156065           intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Stemming...\")\n",
    "test[\"Phrase\"].progress_apply(stem_phrase).head()\n",
    "\n",
    "print(test.shape)\n",
    "test[[\"Phrase\", \"Phrase(origin)\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative,Netural,Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "negative_train = train[train[\"Sentiment\"] < 2]\n",
    "netural_train = train.loc[train.Sentiment == 2]\n",
    "positive_train = train.loc[train.Sentiment > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative vocabluer 구함\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# binary=True/False\n",
    "# lowercase=True/False\n",
    "# ngram_range=(1, 1)\n",
    "# stop_words=None\n",
    "\n",
    "# vectorizer = CountVectorizer(max_features=1000)\n",
    "#stop_vectorizer = CountVectorizer(ngram_range=(1,3),max_df=0.5)\n",
    "stop_vectorizer = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(1, 3))\n",
    "\n",
    "stop_vectorizer.fit(negative_train[\"Phrase\"])\n",
    "stop_vectorizer.transform(negative_train[\"Phrase\"])\n",
    "\n",
    "stop_words = stop_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaliyah',\n",
       " 'aaliyah in',\n",
       " 'aaliyah in her',\n",
       " 'abandon',\n",
       " 'abandon the',\n",
       " 'abandon the theater',\n",
       " 'abc',\n",
       " 'abhorrent',\n",
       " 'ability',\n",
       " 'ability to',\n",
       " 'ability to think',\n",
       " 'able',\n",
       " 'able project',\n",
       " 'able to',\n",
       " 'able to muster',\n",
       " 'abomination',\n",
       " 'abomination mean',\n",
       " 'abomination mean alabama',\n",
       " 'aborted',\n",
       " 'aborted attempts',\n",
       " 'about',\n",
       " 'about an',\n",
       " 'about and',\n",
       " 'about and is',\n",
       " 'about any',\n",
       " 'about any aspect',\n",
       " 'about as',\n",
       " 'about as convincing',\n",
       " 'about as if',\n",
       " 'about bad',\n",
       " 'about bad cinema',\n",
       " 'about being',\n",
       " 'about cinema',\n",
       " 'about cinema only',\n",
       " 'about crass',\n",
       " 'about crass jaded',\n",
       " 'about crime',\n",
       " 'about every',\n",
       " 'about every cliche',\n",
       " 'about god',\n",
       " 'about god is',\n",
       " 'about growing',\n",
       " 'about growing up',\n",
       " 'about his',\n",
       " 'about how',\n",
       " 'about how lame',\n",
       " 'about human',\n",
       " 'about human infidelity',\n",
       " 'about ignoring',\n",
       " 'about ignoring what',\n",
       " 'about it',\n",
       " 'about it by',\n",
       " 'about its',\n",
       " 'about its titular',\n",
       " 'about making',\n",
       " 'about making movie',\n",
       " 'about mary',\n",
       " 'about minutes',\n",
       " 'about minutes of',\n",
       " 'about nothing',\n",
       " 'about nothing at',\n",
       " 'about nothing delivered',\n",
       " 'about one',\n",
       " 'about rubbo',\n",
       " 'about rubbo dumbed',\n",
       " 'about schmidt',\n",
       " 'about schmidt rrb',\n",
       " 'about sex',\n",
       " 'about sex gags',\n",
       " 'about six',\n",
       " 'about six gags',\n",
       " 'about street',\n",
       " 'about street gangs',\n",
       " 'about the',\n",
       " 'about the film',\n",
       " 'about the swinging',\n",
       " 'about their',\n",
       " 'about their cruel',\n",
       " 'about their lives',\n",
       " 'about themselves',\n",
       " 'about this',\n",
       " 'about this movie',\n",
       " 'about what',\n",
       " 'about whose',\n",
       " 'about whose fate',\n",
       " 'about women',\n",
       " 'about women and',\n",
       " 'above',\n",
       " 'above its',\n",
       " 'above the',\n",
       " 'above the level',\n",
       " 'abrupt',\n",
       " 'abrupt drop',\n",
       " 'abrupt turn',\n",
       " 'abrupt turn into',\n",
       " 'absolute',\n",
       " 'absolute last',\n",
       " 'absolute last thing',\n",
       " 'absolutely',\n",
       " 'absorbed',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurd finale',\n",
       " 'absurd lengths',\n",
       " 'absurd plot',\n",
       " 'absurd plot twists',\n",
       " 'absurdist',\n",
       " 'absurdities',\n",
       " 'absurdities and',\n",
       " 'absurdity',\n",
       " 'absurdity of',\n",
       " 'absurdity of the',\n",
       " 'absurdly',\n",
       " 'absurdly inappropriate',\n",
       " 'absurdly inappropriate comedy',\n",
       " 'absurdly simplistic',\n",
       " 'absurdly simplistic picture',\n",
       " 'abundant',\n",
       " 'abundant supply',\n",
       " 'abundant supply in',\n",
       " 'abuse',\n",
       " 'abyss',\n",
       " 'academy',\n",
       " 'academy award',\n",
       " 'academy award winning',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accents performing',\n",
       " 'accents performing ages',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accompanying',\n",
       " 'account',\n",
       " 'account of',\n",
       " 'accurate',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accused of',\n",
       " 'accused of being',\n",
       " 'achieve',\n",
       " 'achieve the',\n",
       " 'achievement',\n",
       " 'achieves',\n",
       " 'achieves the',\n",
       " 'achingly',\n",
       " 'acidic',\n",
       " 'acidic all',\n",
       " 'acidic all male',\n",
       " 'across',\n",
       " 'across as',\n",
       " 'across as both',\n",
       " 'across as shallow',\n",
       " 'across its',\n",
       " 'across its indulgent',\n",
       " 'act',\n",
       " 'act like',\n",
       " 'act like pinocchio',\n",
       " 'act only',\n",
       " 'act the',\n",
       " 'act the other',\n",
       " 'acted',\n",
       " 'acted but',\n",
       " 'acting',\n",
       " 'acting ambition',\n",
       " 'acting ambition but',\n",
       " 'acting and',\n",
       " 'acting by',\n",
       " 'acting by the',\n",
       " 'acting chops',\n",
       " 'acting chops but',\n",
       " 'acting dull',\n",
       " 'acting dull exposition',\n",
       " 'acting from',\n",
       " 'acting from ms',\n",
       " 'acting is',\n",
       " 'acting is amateurish',\n",
       " 'acting is robotically',\n",
       " 'acting lessons',\n",
       " 'acting lessons and',\n",
       " 'acting like',\n",
       " 'acting like an',\n",
       " 'acting like puppets',\n",
       " 'acting poorly',\n",
       " 'acting poorly dubbed',\n",
       " 'acting talents',\n",
       " 'acting that',\n",
       " 'acting that could',\n",
       " 'acting to',\n",
       " 'acting to the',\n",
       " 'acting transfigures',\n",
       " 'acting transfigures esther',\n",
       " 'action',\n",
       " 'action almost',\n",
       " 'action and',\n",
       " 'action cliches',\n",
       " 'action comedies',\n",
       " 'action comedies have',\n",
       " 'action comedy',\n",
       " 'action confined',\n",
       " 'action confined to',\n",
       " 'action film',\n",
       " 'action film disguised',\n",
       " 'action films',\n",
       " 'action films when',\n",
       " 'action flick',\n",
       " 'action flick formula',\n",
       " 'action hero',\n",
       " 'action is',\n",
       " 'action is stilted',\n",
       " 'action movie',\n",
       " 'action movie line',\n",
       " 'action movie production',\n",
       " 'action over',\n",
       " 'action over the',\n",
       " 'action pieces',\n",
       " 'action scenes',\n",
       " 'action sequences',\n",
       " 'action sequences and',\n",
       " 'action set',\n",
       " 'action speeds',\n",
       " 'action speeds up',\n",
       " 'action strongly',\n",
       " 'action strongly reminiscent',\n",
       " 'action twaddle',\n",
       " 'actor',\n",
       " 'actor of',\n",
       " 'actor of talent',\n",
       " 'actor phones',\n",
       " 'actor phones in',\n",
       " 'actor rrb',\n",
       " 'actor rrb succumb',\n",
       " 'actor to',\n",
       " 'actor to lead',\n",
       " 'actor workshops',\n",
       " 'actor workshops and',\n",
       " 'actor would',\n",
       " 'actor would stoop',\n",
       " 'actorliness',\n",
       " 'actors',\n",
       " 'actors even',\n",
       " 'actors even kingsley',\n",
       " 'actors in',\n",
       " 'actors in the',\n",
       " 'actors morgan',\n",
       " 'actors morgan freeman',\n",
       " 'actors reaching',\n",
       " 'actors reaching for',\n",
       " 'actors you',\n",
       " 'actors you re',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actresses lrb',\n",
       " 'actresses lrb and',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actual material',\n",
       " 'actually',\n",
       " 'actually amusing',\n",
       " 'actually exploiting',\n",
       " 'actually exploiting it',\n",
       " 'actually finding',\n",
       " 'actually finding the',\n",
       " 'actually funny',\n",
       " 'actually having',\n",
       " 'actually having hard',\n",
       " 'actually hit',\n",
       " 'actually hit something',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adam sandler',\n",
       " 'adam sandler new',\n",
       " 'adams',\n",
       " 'adams just',\n",
       " 'adams just copies',\n",
       " 'adaptation',\n",
       " 'adaptation of',\n",
       " 'add',\n",
       " 'add up',\n",
       " 'add up to',\n",
       " 'added',\n",
       " 'added disdain',\n",
       " 'added disdain for',\n",
       " 'addition',\n",
       " 'addition of',\n",
       " 'addition of wholly',\n",
       " 'addition to',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adequate babysitter',\n",
       " 'adequate babysitter for',\n",
       " 'adhering',\n",
       " 'adhering to',\n",
       " 'adhering to the',\n",
       " 'admirable',\n",
       " 'admire',\n",
       " 'admire the',\n",
       " 'admit',\n",
       " 'admit that',\n",
       " 'admittedly',\n",
       " 'adolescent',\n",
       " 'adolescent electra',\n",
       " 'adolescent electra rebellion',\n",
       " 'adrift',\n",
       " 'adrift in',\n",
       " 'adrift in various',\n",
       " 'adult',\n",
       " 'adult who',\n",
       " 'adult who apparently',\n",
       " 'adultery',\n",
       " 'adults',\n",
       " 'adults and',\n",
       " 'adults behave',\n",
       " 'adults behave like',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventures of',\n",
       " 'adventures of direct',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'advised to',\n",
       " 'affair',\n",
       " 'affected',\n",
       " 'affected child',\n",
       " 'affected child acting',\n",
       " 'affection',\n",
       " 'affection for',\n",
       " 'affection for the',\n",
       " 'affirming',\n",
       " 'affleck',\n",
       " 'affleck seem',\n",
       " 'affleck seem downright',\n",
       " 'afghan',\n",
       " 'afraid',\n",
       " 'afraid of',\n",
       " 'afraid of the',\n",
       " 'african',\n",
       " 'african americans',\n",
       " 'african americans because',\n",
       " 'after',\n",
       " 'after an',\n",
       " 'after an all',\n",
       " 'after an minute',\n",
       " 'after another',\n",
       " 'after being',\n",
       " 'after few',\n",
       " 'after it',\n",
       " 'after next',\n",
       " 'after oedekerk',\n",
       " 'after school',\n",
       " 'after school special',\n",
       " 'after school tv',\n",
       " 'after the',\n",
       " 'after while',\n",
       " 'aftertaste',\n",
       " 'aftertaste but',\n",
       " 'aftertaste but little',\n",
       " 'afterthought',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'again and',\n",
       " 'again and again',\n",
       " 'again as',\n",
       " 'again as in',\n",
       " 'again ego',\n",
       " 'again ego does',\n",
       " 'again if',\n",
       " 'again if they',\n",
       " 'again that',\n",
       " 'against',\n",
       " 'against farce',\n",
       " 'against farce thoughtful',\n",
       " 'against itself',\n",
       " 'against the',\n",
       " 'age',\n",
       " 'age and',\n",
       " 'age import',\n",
       " 'age import from',\n",
       " 'aged',\n",
       " 'aged romance',\n",
       " 'aged romance rrb',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agent jack',\n",
       " 'agent jack ryan',\n",
       " 'ages',\n",
       " 'ages old',\n",
       " 'ages old slapstick',\n",
       " 'aggressively',\n",
       " 'aggressively anti',\n",
       " 'aggressively anti erotic',\n",
       " 'aging',\n",
       " 'aging filmmaker',\n",
       " 'aging filmmaker still',\n",
       " 'agitprop',\n",
       " 'agitprop and',\n",
       " 'agitprop and the',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'ah',\n",
       " 'ai',\n",
       " 'ai not',\n",
       " 'ai not she',\n",
       " 'aids',\n",
       " 'aids yet',\n",
       " 'ailments',\n",
       " 'aimed',\n",
       " 'aimed at',\n",
       " 'aimless',\n",
       " 'aimless arduous',\n",
       " 'aimless hodgepodge',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'aims for',\n",
       " 'aims so',\n",
       " 'aims so low',\n",
       " 'air',\n",
       " 'air conditioning',\n",
       " 'air of',\n",
       " 'airhead',\n",
       " 'airhead movie',\n",
       " 'airhead movie business',\n",
       " 'airless',\n",
       " 'aisle',\n",
       " 'aisle walker',\n",
       " 'aisle walker and',\n",
       " 'akin',\n",
       " 'akin to',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alabama is',\n",
       " 'alarming',\n",
       " 'album',\n",
       " 'alfred',\n",
       " 'alfred hitchcock',\n",
       " 'alice',\n",
       " 'alienate',\n",
       " 'alienate the',\n",
       " 'alienate the mainstream',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'aliens laser',\n",
       " 'aliens laser guns',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'alive in',\n",
       " 'alive in this',\n",
       " 'all',\n",
       " 'all about',\n",
       " 'all about the',\n",
       " 'all around',\n",
       " 'all as',\n",
       " 'all as very',\n",
       " 'all awkward',\n",
       " 'all awkward static',\n",
       " 'all barely',\n",
       " 'all barely anything',\n",
       " 'all before',\n",
       " 'all but',\n",
       " 'all but ruined',\n",
       " 'all by',\n",
       " 'all by stuffing',\n",
       " 'all can',\n",
       " 'all can not',\n",
       " 'all cylinders',\n",
       " 'all fears',\n",
       " 'all fears starring',\n",
       " 'all for',\n",
       " 'all good',\n",
       " 'all he',\n",
       " 'all inclusive',\n",
       " 'all inclusive world',\n",
       " 'all its',\n",
       " 'all its byzantine',\n",
       " 'all its vital',\n",
       " 'all male',\n",
       " 'all manner',\n",
       " 'all manner of',\n",
       " 'all night',\n",
       " 'all night tequila',\n",
       " 'all of',\n",
       " 'all of his',\n",
       " 'all of its',\n",
       " 'all of pootie',\n",
       " 'all of that',\n",
       " 'all of the',\n",
       " 'all of this',\n",
       " 'all over',\n",
       " 'all over again',\n",
       " 'all over the',\n",
       " 'all over this',\n",
       " 'all seriously',\n",
       " 'all that',\n",
       " 'all that great',\n",
       " 'all that the',\n",
       " 'all the',\n",
       " 'all the dramatic',\n",
       " 'all the same',\n",
       " 'all the way',\n",
       " 'all the wrong',\n",
       " 'all these',\n",
       " 'all these distortions',\n",
       " 'all things',\n",
       " 'all things insipid',\n",
       " 'all this',\n",
       " 'all this emotional',\n",
       " 'all those',\n",
       " 'all through',\n",
       " 'all time',\n",
       " 'all time low',\n",
       " 'all too',\n",
       " 'all too familiar',\n",
       " 'all too painfully',\n",
       " 'all too seriously',\n",
       " 'all woman',\n",
       " 'all woman dysfunctional',\n",
       " 'alleged',\n",
       " 'alleged psychological',\n",
       " 'alleged psychological thriller',\n",
       " 'allegedly',\n",
       " 'allegedly inspired',\n",
       " 'allegedly inspired was',\n",
       " 'allen',\n",
       " 'allow',\n",
       " 'allow the',\n",
       " 'allow the suit',\n",
       " 'allowed',\n",
       " 'allowed it',\n",
       " 'allowed it to',\n",
       " 'allowed to',\n",
       " 'allowed to get',\n",
       " 'allows',\n",
       " 'allows him',\n",
       " 'allows him to',\n",
       " 'allows the',\n",
       " 'allows the film',\n",
       " 'almost',\n",
       " 'almost all',\n",
       " 'almost all of',\n",
       " 'almost as',\n",
       " 'almost completely',\n",
       " 'almost completely dry',\n",
       " 'almost entirely',\n",
       " 'almost every',\n",
       " 'almost every frame',\n",
       " 'almost no',\n",
       " 'almost no organic',\n",
       " 'almost nothing',\n",
       " 'almost senseless',\n",
       " 'alone',\n",
       " 'alone and',\n",
       " 'alone and just',\n",
       " 'alone funny',\n",
       " 'alone seek',\n",
       " 'alone seek out',\n",
       " 'alone with',\n",
       " 'alone with toddler',\n",
       " 'along',\n",
       " 'along the',\n",
       " 'along the way',\n",
       " 'already',\n",
       " 'already done',\n",
       " 'already done way',\n",
       " 'already littered',\n",
       " 'already littered with',\n",
       " 'already obscure',\n",
       " 'already obscure demographic',\n",
       " 'already overladen',\n",
       " 'already overladen with',\n",
       " 'already seen',\n",
       " 'already seen that',\n",
       " 'already seen this',\n",
       " 'already tired',\n",
       " 'already tired years',\n",
       " 'also',\n",
       " 'also does',\n",
       " 'also does the',\n",
       " 'also not',\n",
       " 'also not smart',\n",
       " 'also one',\n",
       " 'also seems',\n",
       " 'also seems to',\n",
       " 'also too',\n",
       " 'also too stupid',\n",
       " 'also uninspired',\n",
       " 'alternate',\n",
       " 'although',\n",
       " 'although the',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'always for',\n",
       " 'always for the',\n",
       " 'always go',\n",
       " 'always go hand',\n",
       " 'always work',\n",
       " 'am',\n",
       " 'amateur',\n",
       " 'amateur in',\n",
       " 'amateur in almost',\n",
       " 'amateurish',\n",
       " 'amateurish episode',\n",
       " 'amateurish the',\n",
       " 'amateurish the cinematography',\n",
       " 'amateurishly',\n",
       " 'amazement',\n",
       " 'amazement over',\n",
       " 'amazement over the',\n",
       " 'ambiguous',\n",
       " 'ambiguous ending',\n",
       " 'ambiguous ending seem',\n",
       " 'ambition',\n",
       " 'ambition but',\n",
       " 'ambition but no',\n",
       " 'ambitious',\n",
       " 'ambitious failure',\n",
       " 'ambitious movie',\n",
       " 'ambivalence',\n",
       " 'amble',\n",
       " 'amble down',\n",
       " 'america',\n",
       " 'america knee',\n",
       " 'america knee jerk',\n",
       " 'american',\n",
       " 'american action',\n",
       " 'american beauty',\n",
       " 'american beauty reeks',\n",
       " 'american pie',\n",
       " 'americans',\n",
       " 'americans because',\n",
       " 'americans because of',\n",
       " 'americans will',\n",
       " 'americans will get',\n",
       " 'amid',\n",
       " 'amid the',\n",
       " 'amish',\n",
       " 'amish people',\n",
       " 'amish people alive',\n",
       " 'amnesiac',\n",
       " 'amok',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amount of',\n",
       " 'amount of imagination',\n",
       " 'amount of phony',\n",
       " 'amounts',\n",
       " 'amounts to',\n",
       " 'amounts to little',\n",
       " 'amounts to surprisingly',\n",
       " 'amp',\n",
       " 'amp and',\n",
       " 'amuse',\n",
       " 'amuse or',\n",
       " 'amuse or entertain',\n",
       " 'amused',\n",
       " 'amused by',\n",
       " 'amused by the',\n",
       " 'amused trash',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amusing let',\n",
       " 'amusing let alone',\n",
       " 'amusing nor',\n",
       " 'amusing nor dramatic',\n",
       " 'amusing us',\n",
       " 'amy',\n",
       " 'amy and',\n",
       " 'amy and changing',\n",
       " 'an',\n",
       " 'an abrupt',\n",
       " 'an abrupt turn',\n",
       " 'an absurd',\n",
       " 'an absurd finale',\n",
       " 'an absurdly',\n",
       " 'an absurdly simplistic',\n",
       " 'an acidic',\n",
       " 'an acidic all',\n",
       " 'an action',\n",
       " 'an action film',\n",
       " 'an action movie',\n",
       " 'an actress',\n",
       " 'an actual',\n",
       " 'an admirable',\n",
       " 'an adult',\n",
       " 'an adult who',\n",
       " 'an affected',\n",
       " 'an affected malaise',\n",
       " 'an after',\n",
       " 'an after school',\n",
       " 'an afterthought',\n",
       " 'an aging',\n",
       " 'an aging filmmaker',\n",
       " 'an aimless',\n",
       " 'an aimless hodgepodge',\n",
       " 'an all',\n",
       " 'an all inclusive',\n",
       " 'an all night',\n",
       " 'an all time',\n",
       " 'an all woman',\n",
       " 'an almost',\n",
       " 'an already',\n",
       " 'an already obscure',\n",
       " 'an amateurish',\n",
       " 'an ambitious',\n",
       " 'an ambitious failure',\n",
       " 'an american',\n",
       " 'an amusement',\n",
       " 'an animated',\n",
       " 'an animated holiday',\n",
       " 'an animatronic',\n",
       " 'an anticipated',\n",
       " 'an anticipated audience',\n",
       " 'an appalling',\n",
       " 'an artist',\n",
       " 'an artist who',\n",
       " 'an astonishingly',\n",
       " 'an astonishingly condescending',\n",
       " 'an astonishingly witless',\n",
       " 'an atmosphere',\n",
       " 'an atmosphere of',\n",
       " 'an atrociously',\n",
       " 'an atrociously mind',\n",
       " 'an attempt',\n",
       " 'an attempt at',\n",
       " 'an attempt to',\n",
       " 'an attention',\n",
       " 'an attention span',\n",
       " 'an audience',\n",
       " 'an audience full',\n",
       " 'an audience intelligence',\n",
       " 'an autopilot',\n",
       " 'an autopilot hollywood',\n",
       " 'an awful',\n",
       " 'an awkwardly',\n",
       " 'an easy',\n",
       " 'an electric',\n",
       " 'an electric pencil',\n",
       " 'an emotional',\n",
       " 'an empty',\n",
       " 'an endorsement',\n",
       " 'an endorsement of',\n",
       " 'an entire',\n",
       " 'an entire olympic',\n",
       " 'an entirely',\n",
       " 'an entirely foreign',\n",
       " 'an entirely stale',\n",
       " 'an episode',\n",
       " 'an episode of',\n",
       " 'an equally',\n",
       " 'an equally miserable',\n",
       " 'an even',\n",
       " 'an even less',\n",
       " 'an eviction',\n",
       " 'an eviction notice',\n",
       " 'an evil',\n",
       " 'an evil monstrous',\n",
       " 'an excellent',\n",
       " 'an exceptionally',\n",
       " 'an excruciating',\n",
       " 'an excuse',\n",
       " 'an exercise',\n",
       " 'an exercise in',\n",
       " 'an exhilarating',\n",
       " 'an expiration',\n",
       " 'an expiration date',\n",
       " 'an exploitation',\n",
       " 'an exploitation piece',\n",
       " 'an exploration',\n",
       " 'an exploration of',\n",
       " 'an extended',\n",
       " 'an extra',\n",
       " 'an extra dry',\n",
       " 'an extremely',\n",
       " 'an hour',\n",
       " 'an hour and',\n",
       " 'an hour in',\n",
       " 'an hour long',\n",
       " 'an hour setting',\n",
       " 'an hour worth',\n",
       " 'an iceberg',\n",
       " 'an iceberg melt',\n",
       " 'an idea',\n",
       " 'an idea buried',\n",
       " 'an idea just',\n",
       " 'an ill',\n",
       " 'an important',\n",
       " 'an important film',\n",
       " 'an impossible',\n",
       " 'an impossible spot',\n",
       " 'an impression',\n",
       " 'an inarticulate',\n",
       " 'an inarticulate screenplay',\n",
       " 'an inconsistent',\n",
       " 'an inconsistent and',\n",
       " 'an inconsistent meandering',\n",
       " 'an incredibly',\n",
       " 'an inelegant',\n",
       " 'an inelegant combination',\n",
       " 'an inexplicable',\n",
       " 'an infomercial',\n",
       " 'an infomercial for',\n",
       " 'an inhalant',\n",
       " 'an inhalant blackout',\n",
       " 'an insult',\n",
       " 'an insult to',\n",
       " 'an insultingly',\n",
       " 'an insultingly inept',\n",
       " 'an interesting',\n",
       " 'an interesting character',\n",
       " 'an intricate',\n",
       " 'an intricate plot',\n",
       " 'an irrepressible',\n",
       " 'an irrepressible passion',\n",
       " 'an minute',\n",
       " 'an minute rip',\n",
       " 'an object',\n",
       " 'an object of',\n",
       " 'an obligation',\n",
       " 'an odd',\n",
       " 'an oily',\n",
       " 'an oily arms',\n",
       " 'an old',\n",
       " 'an older',\n",
       " 'an opportunity',\n",
       " 'an opportunity to',\n",
       " 'an ordeal',\n",
       " 'an ordeal than',\n",
       " 'an original',\n",
       " 'an original bone',\n",
       " 'an original character',\n",
       " 'an original idea',\n",
       " 'an oscar',\n",
       " 'an otherwise',\n",
       " 'an outline',\n",
       " 'an outline for',\n",
       " 'an overexposed',\n",
       " 'an overexposed waste',\n",
       " 'an overflowing',\n",
       " 'an overflowing septic',\n",
       " 'an overly',\n",
       " 'an overly familiar',\n",
       " 'an overly sillified',\n",
       " 'an overripe',\n",
       " 'an overripe episode',\n",
       " 'an rrb',\n",
       " 'an rrb exceedingly',\n",
       " 'an ugly',\n",
       " 'an ugly mean',\n",
       " 'an ultra',\n",
       " 'an ultra loud',\n",
       " 'an unbalanced',\n",
       " 'an unbalanced mixture',\n",
       " 'an unchanged',\n",
       " 'an unchanged dullard',\n",
       " 'an uncomfortable',\n",
       " 'an uncomfortable movie',\n",
       " 'an underdone',\n",
       " 'an underdone potato',\n",
       " 'an undistinguished',\n",
       " 'an uneasy',\n",
       " 'an uneasy marriage',\n",
       " 'an uneven',\n",
       " 'an ungainly',\n",
       " 'an ungainly movie',\n",
       " 'an unhappy',\n",
       " 'an unhappy situation',\n",
       " 'an unimaginative',\n",
       " 'an unimaginative screenwriter',\n",
       " 'an unlimited',\n",
       " 'an unlimited amount',\n",
       " 'an unrewarding',\n",
       " 'an unrewarding collar',\n",
       " 'an unschooled',\n",
       " 'an unschooled comedy',\n",
       " 'an unsettling',\n",
       " 'an unsettling sight',\n",
       " 'an unsympathetic',\n",
       " 'an unsympathetic hero',\n",
       " 'an utterly',\n",
       " 'an utterly incompetent',\n",
       " 'an year',\n",
       " 'an year old',\n",
       " 'anachronistic',\n",
       " 'analysis',\n",
       " 'analysis could',\n",
       " 'analysis could never',\n",
       " 'analyze',\n",
       " 'analyze that',\n",
       " 'analyze that promised',\n",
       " 'analyze this',\n",
       " 'analyze this lrb',\n",
       " 'anatomical',\n",
       " 'anatomical humor',\n",
       " 'and',\n",
       " 'and abstract',\n",
       " 'and absurd',\n",
       " 'and acting',\n",
       " 'and adults',\n",
       " 'and again',\n",
       " 'and agitator',\n",
       " 'and all',\n",
       " 'and all that',\n",
       " 'and allows',\n",
       " 'and allows the',\n",
       " 'and almost',\n",
       " 'and amateurish',\n",
       " 'and an',\n",
       " 'and an equally',\n",
       " 'and an hour',\n",
       " 'and an insult',\n",
       " 'and analyze',\n",
       " 'and analyze that',\n",
       " 'and animal',\n",
       " 'and animal gibberish',\n",
       " 'and ankle',\n",
       " 'and ankle deep',\n",
       " 'and annoying',\n",
       " 'and annoying stereotypes',\n",
       " 'and another',\n",
       " 'and another night',\n",
       " 'and any',\n",
       " 'and any naked',\n",
       " 'and are',\n",
       " 'and are defeated',\n",
       " 'and arrogance',\n",
       " 'and arrogance of',\n",
       " 'and artificial',\n",
       " 'and artificial examination',\n",
       " 'and as',\n",
       " 'and as bland',\n",
       " 'and as easy',\n",
       " 'and ashley',\n",
       " 'and ashley judd',\n",
       " 'and ask',\n",
       " 'and ask permission',\n",
       " 'and asks',\n",
       " 'and asks to',\n",
       " 'and at',\n",
       " 'and at times',\n",
       " 'and authentic',\n",
       " 'and authentic christmas',\n",
       " 'and awful',\n",
       " 'and bad',\n",
       " 'and bad acting',\n",
       " 'and become',\n",
       " 'and becomes',\n",
       " 'and begins',\n",
       " 'and believable',\n",
       " 'and believable and',\n",
       " 'and big',\n",
       " 'and big wave',\n",
       " 'and bile',\n",
       " 'and bit',\n",
       " 'and bit contrived',\n",
       " 'and black',\n",
       " 'and black comedy',\n",
       " 'and blacked',\n",
       " 'and blacked out',\n",
       " 'and blood',\n",
       " 'and blood humans',\n",
       " 'and blurry',\n",
       " 'and blurry to',\n",
       " 'and bogs',\n",
       " 'and bogs down',\n",
       " 'and borderline',\n",
       " 'and borderline insulting',\n",
       " 'and bored',\n",
       " 'and boring',\n",
       " 'and bouts',\n",
       " 'and bouts of',\n",
       " 'and brits',\n",
       " 'and bronx',\n",
       " 'and bronx tale',\n",
       " 'and bruce',\n",
       " 'and bruce willis',\n",
       " 'and by',\n",
       " 'and carried',\n",
       " 'and carried out',\n",
       " 'and cartoonish',\n",
       " 'and celluloid',\n",
       " 'and change',\n",
       " 'and change watching',\n",
       " 'and changing',\n",
       " 'and changing lanes',\n",
       " 'and characters',\n",
       " 'and characters that',\n",
       " 'and characters to',\n",
       " 'and charisma',\n",
       " 'and charmless',\n",
       " 'and cheese',\n",
       " 'and chilly',\n",
       " 'and choose',\n",
       " 'and choose to',\n",
       " 'and choppy',\n",
       " 'and choppy recycling',\n",
       " 'and cliche',\n",
       " 'and cloying',\n",
       " 'and clumsily',\n",
       " 'and comes',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 2 ~3 \n",
    "#netu_vectorizer = CountVectorizer(ngram_range=(1,3),max_df=0.5)\n",
    "netu_vectorizer = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(1, 3))\n",
    "\n",
    "netu_vectorizer.fit(netural_train[\"Phrase\"])\n",
    "netu_vectorizer.transform(netural_train[\"Phrase\"])\n",
    "\n",
    "netu_words = netu_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaliyah',\n",
       " 'abagnale',\n",
       " 'abagnale antics',\n",
       " 'abandon',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abdul',\n",
       " 'abdul malik',\n",
       " 'abdul malik abbott',\n",
       " 'abel',\n",
       " 'abhors',\n",
       " 'ability',\n",
       " 'ability to',\n",
       " 'ability to bore',\n",
       " 'abject',\n",
       " 'abject suffering',\n",
       " 'able',\n",
       " 'able to',\n",
       " 'able to muster',\n",
       " 'ably',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'about all',\n",
       " 'about all the',\n",
       " 'about an',\n",
       " 'about an inhuman',\n",
       " 'about anything',\n",
       " 'about artifice',\n",
       " 'about artifice and',\n",
       " 'about as',\n",
       " 'about bad',\n",
       " 'about bad company',\n",
       " 'about being',\n",
       " 'about being stupid',\n",
       " 'about black',\n",
       " 'about black urban',\n",
       " 'about cal',\n",
       " 'about campus',\n",
       " 'about campus depravity',\n",
       " 'about chicago',\n",
       " 'about chicago in',\n",
       " 'about contract',\n",
       " 'about contract on',\n",
       " 'about critical',\n",
       " 'about critical reaction',\n",
       " 'about documentaries',\n",
       " 'about documentaries in',\n",
       " 'about drug',\n",
       " 'about drug dealers',\n",
       " 'about entrapment',\n",
       " 'about entrapment in',\n",
       " 'about eve',\n",
       " 'about everything',\n",
       " 'about existential',\n",
       " 'about existential suffering',\n",
       " 'about family',\n",
       " 'about fear',\n",
       " 'about fear dot',\n",
       " 'about girls',\n",
       " 'about growing',\n",
       " 'about growing up',\n",
       " 'about guys',\n",
       " 'about half',\n",
       " 'about her',\n",
       " 'about him',\n",
       " 'about his',\n",
       " 'about his responsibility',\n",
       " 'about how',\n",
       " 'about how in',\n",
       " 'about how show',\n",
       " 'about human',\n",
       " 'about human darkness',\n",
       " 'about in',\n",
       " 'about inner',\n",
       " 'about inner consciousness',\n",
       " 'about iran',\n",
       " 'about iran electoral',\n",
       " 'about it',\n",
       " 'about italian',\n",
       " 'about italian chinese',\n",
       " 'about its',\n",
       " 'about its protagonist',\n",
       " 'about its subjects',\n",
       " 'about lily',\n",
       " 'about lily chou',\n",
       " 'about mary',\n",
       " 'about mary and',\n",
       " 'about men',\n",
       " 'about modern',\n",
       " 'about modern man',\n",
       " 'about most',\n",
       " 'about most of',\n",
       " 'about murder',\n",
       " 'about murder by',\n",
       " 'about nothing',\n",
       " 'about one',\n",
       " 'about one thing',\n",
       " 'about others',\n",
       " 'about others outside',\n",
       " 'about our',\n",
       " 'about our knowledge',\n",
       " 'about overachieving',\n",
       " 'about percentages',\n",
       " 'about percentages all',\n",
       " 'about ravishing',\n",
       " 'about ravishing costumes',\n",
       " 'about reign',\n",
       " 'about reign of',\n",
       " 'about schmidt',\n",
       " 'about something',\n",
       " 'about something and',\n",
       " 'about space',\n",
       " 'about space travel',\n",
       " 'about specific',\n",
       " 'about specific scary',\n",
       " 'about spirited',\n",
       " 'about spirited away',\n",
       " 'about stealing',\n",
       " 'about stealing harvard',\n",
       " 'about suffering',\n",
       " 'about suffering afghan',\n",
       " 'about telemarketers',\n",
       " 'about ten',\n",
       " 'about ten feet',\n",
       " 'about that',\n",
       " 'about the',\n",
       " 'about the bottom',\n",
       " 'about the characters',\n",
       " 'about the death',\n",
       " 'about the film',\n",
       " 'about the hypocrisies',\n",
       " 'about the image',\n",
       " 'about the new',\n",
       " 'about the original',\n",
       " 'about the peril',\n",
       " 'about the relationships',\n",
       " 'about the silences',\n",
       " 'about the source',\n",
       " 'about the subject',\n",
       " 'about the truth',\n",
       " 'about the vietnam',\n",
       " 'about the war',\n",
       " 'about the ways',\n",
       " 'about their',\n",
       " 'about their daily',\n",
       " 'about their genitals',\n",
       " 'about their lives',\n",
       " 'about them',\n",
       " 'about them anyway',\n",
       " 'about thirty',\n",
       " 'about thirty seconds',\n",
       " 'about this',\n",
       " 'about those',\n",
       " 'about those years',\n",
       " 'about three',\n",
       " 'about to',\n",
       " 'about to burst',\n",
       " 'about two',\n",
       " 'about vampire',\n",
       " 'about vicarious',\n",
       " 'about vicarious redemption',\n",
       " 'about what',\n",
       " 'about what going',\n",
       " 'about what happened',\n",
       " 'about whimsical',\n",
       " 'about whimsical folk',\n",
       " 'about women',\n",
       " 'about writers',\n",
       " 'about young',\n",
       " 'above',\n",
       " 'above average',\n",
       " 'above its',\n",
       " 'above manhattan',\n",
       " 'above the',\n",
       " 'above the stale',\n",
       " 'abrahams',\n",
       " 'abrahams films',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorbs all',\n",
       " 'absorbs all manner',\n",
       " 'absorption',\n",
       " 'abstract',\n",
       " 'abstract and',\n",
       " 'abstract and excruciatingly',\n",
       " 'abstract terms',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'academy award',\n",
       " 'academy flicks',\n",
       " 'accent',\n",
       " 'accent uma',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptable teen',\n",
       " 'acceptable teen entertainment',\n",
       " 'accepts',\n",
       " 'accepts the',\n",
       " 'accepts the news',\n",
       " 'access',\n",
       " 'access to',\n",
       " 'access to the',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessible for',\n",
       " 'accessible for non',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accommodate',\n",
       " 'accommodate to',\n",
       " 'accommodate to fit',\n",
       " 'accompanies',\n",
       " 'accompanies didactic',\n",
       " 'accompanies didactic entertainment',\n",
       " 'accomplished',\n",
       " 'accomplishments',\n",
       " 'according',\n",
       " 'according to',\n",
       " 'according to the',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuse',\n",
       " 'acerbic',\n",
       " 'acerbic repartee',\n",
       " 'ache',\n",
       " 'ache with',\n",
       " 'ache with sadness',\n",
       " 'achero',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achingly',\n",
       " 'achronological',\n",
       " 'acidic',\n",
       " 'acidic all',\n",
       " 'acidic all male',\n",
       " 'acknowledges',\n",
       " 'acolytes',\n",
       " 'acquainted',\n",
       " 'acquainted with',\n",
       " 'acquainted with the',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquired taste',\n",
       " 'across',\n",
       " 'across america',\n",
       " 'across america winter',\n",
       " 'across its',\n",
       " 'across its borders',\n",
       " 'across the',\n",
       " 'across these',\n",
       " 'across these days',\n",
       " 'across time',\n",
       " 'across time and',\n",
       " 'act',\n",
       " 'act like',\n",
       " 'act like pinocchio',\n",
       " 'act miscalculation',\n",
       " 'act of',\n",
       " 'acted',\n",
       " 'acted and',\n",
       " 'acted but',\n",
       " 'acted out',\n",
       " 'acting',\n",
       " 'acting and',\n",
       " 'acting chops',\n",
       " 'acting exercise',\n",
       " 'acting transfigures',\n",
       " 'acting workshop',\n",
       " 'acting workshop exercises',\n",
       " 'action',\n",
       " 'action adventure',\n",
       " 'action and',\n",
       " 'action at',\n",
       " 'action at the',\n",
       " 'action cheese',\n",
       " 'action cheese ham',\n",
       " 'action comedy',\n",
       " 'action film',\n",
       " 'action films',\n",
       " 'action flick',\n",
       " 'action flicks',\n",
       " 'action genre',\n",
       " 'action genre but',\n",
       " 'action hero',\n",
       " 'action laudable',\n",
       " 'action movie',\n",
       " 'action or',\n",
       " 'action or buddy',\n",
       " 'action oriented',\n",
       " 'action over',\n",
       " 'action over the',\n",
       " 'action packed',\n",
       " 'action picture',\n",
       " 'action scenes',\n",
       " 'action sequences',\n",
       " 'action thriller',\n",
       " 'action tv',\n",
       " 'action tv series',\n",
       " 'actions',\n",
       " 'actions and',\n",
       " 'actions and revelations',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actor and',\n",
       " 'actor and the',\n",
       " 'actor phones',\n",
       " 'actor rrb',\n",
       " 'actor who',\n",
       " 'actorly',\n",
       " 'actors',\n",
       " 'actors in',\n",
       " 'actors in the',\n",
       " 'actors involved',\n",
       " 'actors lrb',\n",
       " 'actors lrb dawson',\n",
       " 'actors performances',\n",
       " 'actress',\n",
       " 'actress and',\n",
       " 'actress even',\n",
       " 'actress who',\n",
       " 'actress who smiles',\n",
       " 'actresses',\n",
       " 'actresses in',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actual material',\n",
       " 'actual story',\n",
       " 'actual vietnam',\n",
       " 'actual vietnam war',\n",
       " 'actually',\n",
       " 'actually done',\n",
       " 'actually funny',\n",
       " 'actually movie',\n",
       " 'actually movie folk',\n",
       " 'actually one',\n",
       " 'actually one correct',\n",
       " 'actually produced',\n",
       " 'actually produced by',\n",
       " 'actually pulling',\n",
       " 'actually pulling it',\n",
       " 'actually taken',\n",
       " 'actually taken over',\n",
       " 'actually tell',\n",
       " 'actually tell story',\n",
       " 'ad',\n",
       " 'ad and',\n",
       " 'ad and as',\n",
       " 'ad man',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adam sandler',\n",
       " 'adam sandler chanukah',\n",
       " 'adams',\n",
       " 'adams quietly',\n",
       " 'adams quietly freaking',\n",
       " 'adaptation',\n",
       " 'adaptation of',\n",
       " 'adaptation of evans',\n",
       " 'adaptation of the',\n",
       " 'adapted',\n",
       " 'add',\n",
       " 'add to',\n",
       " 'add to the',\n",
       " 'add up',\n",
       " 'add up to',\n",
       " 'addams',\n",
       " 'addams family',\n",
       " 'addams family to',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addition',\n",
       " 'addition of',\n",
       " 'addition of biblical',\n",
       " 'address',\n",
       " 'addresses',\n",
       " 'addresses current',\n",
       " 'addresses current terrorism',\n",
       " 'addressing',\n",
       " 'addressing the',\n",
       " 'addressing the turn',\n",
       " 'adds',\n",
       " 'adds period',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adherents',\n",
       " 'adherents on',\n",
       " 'adherents on either',\n",
       " 'adjusting',\n",
       " 'administration',\n",
       " 'administration complicity',\n",
       " 'administration complicity in',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admire but',\n",
       " 'admire the',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admit how',\n",
       " 'admit how much',\n",
       " 'admit it',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admittedly broad',\n",
       " 'adolescence',\n",
       " 'adolescence difficult',\n",
       " 'adolescence difficult to',\n",
       " 'adolescent',\n",
       " 'adolescent boys',\n",
       " 'adolescent dirty',\n",
       " 'adolescent dirty joke',\n",
       " 'adolescent electra',\n",
       " 'adolescent electra rebellion',\n",
       " 'adolescent poster',\n",
       " 'adolescent poster boy',\n",
       " 'adolescents',\n",
       " 'adopt',\n",
       " 'adrian',\n",
       " 'adrian lyne',\n",
       " 'adult',\n",
       " 'adult hindsight',\n",
       " 'adult life',\n",
       " 'adults',\n",
       " 'adults and',\n",
       " 'adults and everyone',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'advantage on',\n",
       " 'advantage on cable',\n",
       " 'adventues',\n",
       " 'adventure',\n",
       " 'adventure and',\n",
       " 'adventures',\n",
       " 'adventures of',\n",
       " 'adventurous',\n",
       " 'advertised',\n",
       " 'advertised as',\n",
       " 'advertised as comedy',\n",
       " 'advice',\n",
       " 'advises',\n",
       " 'advises denlopp',\n",
       " 'advises denlopp after',\n",
       " 'aesthetic',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affection for',\n",
       " 'affirming',\n",
       " 'affirming because',\n",
       " 'affirming because it',\n",
       " 'affirming lesson',\n",
       " 'affirming script',\n",
       " 'affleck',\n",
       " 'afflicts',\n",
       " 'afflicts so',\n",
       " 'afflicts so many',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'afghan',\n",
       " 'afghan refugees',\n",
       " 'afghan refugees on',\n",
       " 'afghani',\n",
       " 'afghani refugees',\n",
       " 'aficionados',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'afraid of',\n",
       " 'afraid of biting',\n",
       " 'afraid to',\n",
       " 'afraid to risk',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'african american',\n",
       " 'african coast',\n",
       " 'african empire',\n",
       " 'after',\n",
       " 'after all',\n",
       " 'after another',\n",
       " 'after decades',\n",
       " 'after few',\n",
       " 'after few weeks',\n",
       " 'after greene',\n",
       " 'after greene story',\n",
       " 'after hours',\n",
       " 'after hours loopiness',\n",
       " 'after it',\n",
       " 'after next',\n",
       " 'after next to',\n",
       " 'after rather',\n",
       " 'after rather er',\n",
       " 'after school',\n",
       " 'after school special',\n",
       " 'after seeing',\n",
       " 'after the',\n",
       " 'after the family',\n",
       " 'after two',\n",
       " 'after two years',\n",
       " 'after while',\n",
       " 'after you',\n",
       " 'after you leave',\n",
       " 'afterlife',\n",
       " 'afterlife and',\n",
       " 'afterlife and lot',\n",
       " 'afternoon',\n",
       " 'afternoon with',\n",
       " 'afternoon with cause',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'again',\n",
       " 'again and',\n",
       " 'again even',\n",
       " 'again even though',\n",
       " 'again maintain',\n",
       " 'again maintain straight',\n",
       " 'again resists',\n",
       " 'again resists the',\n",
       " 'against',\n",
       " 'against all',\n",
       " 'against all odds',\n",
       " 'against for',\n",
       " 'against for that',\n",
       " 'against foreign',\n",
       " 'against foreign influences',\n",
       " 'against humanity',\n",
       " 'against the',\n",
       " 'against the urge',\n",
       " 'age',\n",
       " 'age and',\n",
       " 'age as',\n",
       " 'age as in',\n",
       " 'age coming',\n",
       " 'age coming out',\n",
       " 'age does',\n",
       " 'age does not',\n",
       " 'age film',\n",
       " 'age gender',\n",
       " 'age gender race',\n",
       " 'age is',\n",
       " 'age movie',\n",
       " 'age of',\n",
       " 'age tale',\n",
       " 'aged',\n",
       " 'aged romance',\n",
       " 'aged woman',\n",
       " 'agency',\n",
       " 'agency boss',\n",
       " 'agency boss close',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agent',\n",
       " 'agers',\n",
       " 'ages',\n",
       " 'aggrandizing',\n",
       " 'aggrandizing madness',\n",
       " 'aggrandizing madness not',\n",
       " 'aggressive',\n",
       " 'aging',\n",
       " 'agnostic',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agonizing catch',\n",
       " 'agonizing catch glory',\n",
       " 'agony',\n",
       " 'agony of',\n",
       " 'agreement',\n",
       " 'ah',\n",
       " 'ah na',\n",
       " 'ah yes',\n",
       " 'ahead',\n",
       " 'ahead of',\n",
       " 'ahead of the',\n",
       " 'ai',\n",
       " 'ai not',\n",
       " 'aid',\n",
       " 'aid is',\n",
       " 'aid is made',\n",
       " 'aids',\n",
       " 'aids subtext',\n",
       " 'aiello',\n",
       " 'aim',\n",
       " 'aim at',\n",
       " 'aim at contemporary',\n",
       " 'aim the',\n",
       " 'aim the film',\n",
       " 'aimed',\n",
       " 'aimed at',\n",
       " 'aimless',\n",
       " 'aimlessness',\n",
       " 'aims',\n",
       " 'aims to',\n",
       " 'air',\n",
       " 'air conditioning',\n",
       " 'air conditioning inside',\n",
       " 'air of',\n",
       " 'air onscreen',\n",
       " 'aircraft',\n",
       " 'aircraft carrier',\n",
       " 'aisle',\n",
       " 'aisle walker',\n",
       " 'akin',\n",
       " 'akin to',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alacrity',\n",
       " 'aladdin',\n",
       " 'alagna',\n",
       " 'alan',\n",
       " 'alan warner',\n",
       " 'alan warner novel',\n",
       " 'alas',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'album songs',\n",
       " 'alchemical',\n",
       " 'aldrich',\n",
       " 'aleck',\n",
       " 'alert',\n",
       " 'alexander',\n",
       " 'alexander payne',\n",
       " 'alexandre',\n",
       " 'alexandre dumas',\n",
       " 'alexandre dumas classic',\n",
       " 'alfred',\n",
       " 'alfred hitchcock',\n",
       " 'ali',\n",
       " 'ali macgraw',\n",
       " 'ali macgraw profanities',\n",
       " 'alice',\n",
       " 'alice krige',\n",
       " 'alice krige cape',\n",
       " 'alien',\n",
       " 'alien deckhand',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'aliens and',\n",
       " 'aliens and every',\n",
       " 'aliens and super',\n",
       " 'aliens too',\n",
       " 'alive',\n",
       " 'alive when',\n",
       " 'all',\n",
       " 'all about',\n",
       " 'all about eve',\n",
       " 'all about lily',\n",
       " 'all about the',\n",
       " 'all ages',\n",
       " 'all aliens',\n",
       " 'all aliens too',\n",
       " 'all at',\n",
       " 'all at once',\n",
       " 'all before',\n",
       " 'all blown',\n",
       " 'all blown up',\n",
       " 'all but',\n",
       " 'all condition',\n",
       " 'all condition only',\n",
       " 'all costs',\n",
       " 'all day',\n",
       " 'all derivative',\n",
       " 'all end',\n",
       " 'all fears',\n",
       " 'all for',\n",
       " 'all guys',\n",
       " 'all guys got',\n",
       " 'all happened',\n",
       " 'all happened only',\n",
       " 'all he',\n",
       " 'all human',\n",
       " 'all in',\n",
       " 'all in all',\n",
       " 'all in the',\n",
       " 'all it',\n",
       " 'all it seems',\n",
       " 'all its',\n",
       " 'all its agonizing',\n",
       " 'all its odd',\n",
       " 'all its plot',\n",
       " 'all male',\n",
       " 'all manner',\n",
       " 'all manner of',\n",
       " 'all men',\n",
       " 'all men for',\n",
       " 'all odds',\n",
       " 'all of',\n",
       " 'all of his',\n",
       " 'all of its',\n",
       " 'all of me',\n",
       " 'all of that',\n",
       " 'all of the',\n",
       " 'all or',\n",
       " 'all over',\n",
       " 'all places',\n",
       " 'all relationships',\n",
       " 'all spelled',\n",
       " 'all spelled out',\n",
       " 'all star',\n",
       " 'all that',\n",
       " 'all that heaven',\n",
       " 'all that interesting',\n",
       " 'all that jazz',\n",
       " 'all that much',\n",
       " 'all the',\n",
       " 'all the blood',\n",
       " 'all the buttons',\n",
       " 'all the classic',\n",
       " 'all the drama',\n",
       " 'all the emotions',\n",
       " 'all the films',\n",
       " 'all the fuss',\n",
       " 'all the longing',\n",
       " 'all the loss',\n",
       " 'all the movie',\n",
       " 'all the previous',\n",
       " 'all the queen',\n",
       " 'all the spaces',\n",
       " 'all the time',\n",
       " 'all the way',\n",
       " 'all the wrong',\n",
       " 'all these',\n",
       " 'all these distortions',\n",
       " 'all things',\n",
       " 'all this',\n",
       " 'all this strutting',\n",
       " 'all those',\n",
       " 'all those gimmicks',\n",
       " 'all three',\n",
       " 'all times',\n",
       " 'all too',\n",
       " 'all too familiar',\n",
       " 'all too human',\n",
       " 'all work',\n",
       " 'all year',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allen rrb',\n",
       " 'allied',\n",
       " 'allied soldiers',\n",
       " 'allow',\n",
       " 'allow for',\n",
       " 'allow for plenty',\n",
       " 'allow us',\n",
       " 'allow us to',\n",
       " 'allowed',\n",
       " 'allows',\n",
       " 'allows and',\n",
       " 'allows and imitation',\n",
       " 'allows if',\n",
       " 'allows if you',\n",
       " 'allusions',\n",
       " 'allusions to',\n",
       " 'allusions to the',\n",
       " 'almost',\n",
       " 'almost all',\n",
       " 'almost all of',\n",
       " 'almost anachronistic',\n",
       " 'almost as',\n",
       " 'almost dozing',\n",
       " 'almost enough',\n",
       " 'almost every',\n",
       " 'almost makes',\n",
       " 'almost recommending',\n",
       " 'almost recommending it',\n",
       " 'almost sure',\n",
       " 'almost sure fire',\n",
       " 'almost unimaginable',\n",
       " 'almost unimaginable horror',\n",
       " 'almost worth',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'along the',\n",
       " 'along the way',\n",
       " 'along with',\n",
       " 'along with the',\n",
       " 'aloof',\n",
       " 'aloof father',\n",
       " 'aloof father and',\n",
       " 'already',\n",
       " 'already seen',\n",
       " 'already to',\n",
       " 'already to so',\n",
       " 'also',\n",
       " 'also creative',\n",
       " 'also creative urge',\n",
       " 'also dealt',\n",
       " 'also dealt with',\n",
       " 'also does',\n",
       " 'also does it',\n",
       " 'also one',\n",
       " 'also one of',\n",
       " 'also somewhat',\n",
       " 'also the',\n",
       " 'altar',\n",
       " 'altar boys',\n",
       " 'alter',\n",
       " 'alter the',\n",
       " 'alter the bard',\n",
       " 'alternate',\n",
       " 'alternate reality',\n",
       " 'alternate sexuality',\n",
       " 'alternate version',\n",
       " 'alternately',\n",
       " 'alternately comic',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternative housing',\n",
       " 'alternative housing options',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'although the',\n",
       " 'altman',\n",
       " 'altman esque',\n",
       " 'altman spike',\n",
       " 'altman spike lee',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'always ended',\n",
       " 'always ended with',\n",
       " 'always for',\n",
       " 'always for the',\n",
       " 'always like',\n",
       " 'always like that',\n",
       " 'always wanted',\n",
       " 'always wanted to',\n",
       " 'am',\n",
       " 'amalgam',\n",
       " 'amalgam of',\n",
       " 'amalgam of comedy',\n",
       " 'amaro',\n",
       " 'amassed',\n",
       " 'amateurish',\n",
       " 'amazing',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambiguous presentation',\n",
       " 'ambition',\n",
       " 'ambition to',\n",
       " 'ambition to say',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambitious movie',\n",
       " 'ambivalent',\n",
       " 'ambrose',\n",
       " 'america',\n",
       " 'america culture',\n",
       " 'america culture of',\n",
       " 'america indigenous',\n",
       " 'america indigenous people',\n",
       " 'america speaking',\n",
       " 'america speaking not',\n",
       " 'america winter',\n",
       " 'america winter movie',\n",
       " 'american',\n",
       " 'american action',\n",
       " 'american and',\n",
       " 'american and european',\n",
       " 'american beauty',\n",
       " 'american cinema',\n",
       " 'american decision',\n",
       " 'american decision that',\n",
       " 'american director',\n",
       " 'american dream',\n",
       " 'american film',\n",
       " 'american in',\n",
       " 'american indians',\n",
       " 'american life',\n",
       " 'american pie',\n",
       " 'american pie hijinks',\n",
       " 'american pie like',\n",
       " 'american pie movies',\n",
       " 'american professionals',\n",
       " 'american psycho',\n",
       " 'american right',\n",
       " 'american right wing',\n",
       " 'american russian',\n",
       " 'american russian armageddon',\n",
       " 'american scorn',\n",
       " 'american scorn or',\n",
       " 'american sexual',\n",
       " 'american sexual landscape',\n",
       " 'american style',\n",
       " 'american teen',\n",
       " 'american teen comedies',\n",
       " 'american workers',\n",
       " 'american young',\n",
       " 'american young men',\n",
       " 'american zealously',\n",
       " 'americanized',\n",
       " 'americans',\n",
       " 'americans and',\n",
       " 'americans and their',\n",
       " 'amiable',\n",
       " 'amid',\n",
       " 'amid all',\n",
       " 'amid all the',\n",
       " 'amidst',\n",
       " 'amini',\n",
       " 'amir',\n",
       " 'amir mann',\n",
       " 'amnesiac',\n",
       " 'among',\n",
       " 'among partnerships',\n",
       " 'among the',\n",
       " 'amoral',\n",
       " 'amoral assassin',\n",
       " 'amoral assassin just',\n",
       " 'amorous',\n",
       " 'amorous terrier',\n",
       " 'amos',\n",
       " 'amos records',\n",
       " 'amount',\n",
       " 'amount of',\n",
       " 'amount of time',\n",
       " 'amounts',\n",
       " 'amounts to',\n",
       " 'amounts to much',\n",
       " 'amours',\n",
       " 'amp',\n",
       " 'ample',\n",
       " 'ample opportunity',\n",
       " 'ample opportunity to',\n",
       " 'amused',\n",
       " 'amusedly',\n",
       " 'amusedly sometimes',\n",
       " 'amusedly sometimes impatiently',\n",
       " 'amuses',\n",
       " 'amuses but',\n",
       " 'amuses but none',\n",
       " 'amusing',\n",
       " 'amusing but',\n",
       " 'amy',\n",
       " 'amy and',\n",
       " 'amy and changing',\n",
       " 'an',\n",
       " 'an acidic',\n",
       " 'an acidic all',\n",
       " 'an acquired',\n",
       " 'an acquired taste',\n",
       " 'an act',\n",
       " 'an act of',\n",
       " 'an action',\n",
       " 'an action movie',\n",
       " 'an actor',\n",
       " 'an actress',\n",
       " 'an actress who',\n",
       " 'an actual',\n",
       " 'an actual story',\n",
       " 'an actual vietnam',\n",
       " 'an adam',\n",
       " 'an adam sandler',\n",
       " 'an admittedly',\n",
       " 'an adolescent',\n",
       " 'an adolescent dirty',\n",
       " 'an adult',\n",
       " 'an after',\n",
       " 'an after school',\n",
       " 'an afterthought',\n",
       " 'an air',\n",
       " 'an alice',\n",
       " 'an alien',\n",
       " 'an alien deckhand',\n",
       " 'an all',\n",
       " 'an almost',\n",
       " 'an aloof',\n",
       " 'an aloof father',\n",
       " 'an alternate',\n",
       " 'an alternate version',\n",
       " 'an alternative',\n",
       " 'an ambiguous',\n",
       " 'an ambiguous presentation',\n",
       " 'an ambition',\n",
       " 'an ambition to',\n",
       " 'an american',\n",
       " 'an american film',\n",
       " 'an american russian',\n",
       " 'an amiable',\n",
       " 'an amoral',\n",
       " 'an amoral assassin',\n",
       " 'an ancient',\n",
       " 'an ancient faith',\n",
       " 'an angry',\n",
       " 'an angry bark',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netu_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stops world 리스트에서 중복제거하며 합치기\n",
    "stop_words = list(set(stop_words).union(set(netu_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<42133x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 585969 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2 ~3\n",
    "#posi_vectorizer = CountVectorizer(ngram_range=(1,3),max_df=0.5)\n",
    "posi_vectorizer = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(1, 3))\n",
    "posi_vectorizer.fit(positive_train[\"Phrase\"])\n",
    "posi_vectorizer.transform(positive_train[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posi_words = posi_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stops world 리스트에서 중복제거하며 합치기\n",
    "vocabulary = list(set(stop_words).union(set(posi_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=10000, min_df=1,\n",
       "        ngram_range=(1, 9), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(analyzer='char', max_features=10000, ngram_range=(1, 9))\n",
    "char_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=10000, min_df=1,\n",
       "        ngram_range=(1, 9), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vectorizer.fit(train[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<156060x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 20097469 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_char = char_vectorizer.transform(train[\"Phrase\"])\n",
    "X_train_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66292x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7898338 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_char = char_vectorizer.transform(test[\"Phrase\"])\n",
    "X_test_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=['at the door', 'insulting or', 'surfer', 'flowering of the', 'encumbers itself', 'been fumbled by', 'style parody blaxploitation', 'drunk love', 'of jonathan', 'obvious melodrama and', 'however it', 'brilliant and', 'substance it so', 'and the basic', 'move', 'shenanigans in welcome', 'p...'unresolved moral conflict', 'roller coaster', 'mundane', 'industry in', 'sand creeping', 'is mere'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_vectorizer = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(1, 2))\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(1, 3),vocabulary=vocabulary)\n",
    "word_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=['at the door', 'insulting or', 'surfer', 'flowering of the', 'encumbers itself', 'been fumbled by', 'style parody blaxploitation', 'drunk love', 'of jonathan', 'obvious melodrama and', 'however it', 'brilliant and', 'substance it so', 'and the basic', 'move', 'shenanigans in welcome', 'p...'unresolved moral conflict', 'roller coaster', 'mundane', 'industry in', 'sand creeping', 'is mere'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer.fit(train[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<156060x69810 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1868523 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_word = word_vectorizer.transform(train[\"Phrase\"])\n",
    "X_train_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66292x69810 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 501233 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_word = word_vectorizer.transform(test[\"Phrase\"])\n",
    "X_test_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<156060x79810 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21965992 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train = hstack([X_train_char, X_train_word])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66292x79810 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8399571 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = hstack([X_test_char, X_test_word])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns = word_vectorizer.get_feature_names()\n",
    "# pd.DataFrame(X_train.tocsr()[:100].toarray(), columns=columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PhraseId\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "5    2\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train[\"Sentiment\"]\n",
    "\n",
    "print(y_train.shape)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PhraseId\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "Name: SentenceId, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_ids = train[\"SentenceId\"]\n",
    "\n",
    "print(sentence_ids.shape)\n",
    "sentence_ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\big\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=6.762746e-06, average=False, class_weight=None,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=37, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model = SGDClassifier(alpha=0.000006762746, random_state=37)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2, 2, 3, 2, 3, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "y_predict = cross_val_predict(model, X_train, y_train,\n",
    "                              cv=kfold, groups=sentence_ids)\n",
    "\n",
    "print(y_predict.shape)\n",
    "y_predict[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.60164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(y_train, y_predict)\n",
    "print(\"Score = {0:.5f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score = 0.60041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase(origin)</th>\n",
       "      <th>Sentiment(predict)</th>\n",
       "      <th>Difference(Phrase)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment                                     Phrase(origin)  \\\n",
       "PhraseId                                                                 \n",
       "1                 1  A series of escapades demonstrating the adage ...   \n",
       "2                 2  A series of escapades demonstrating the adage ...   \n",
       "3                 2                                           A series   \n",
       "4                 2                                                  A   \n",
       "5                 2                                             series   \n",
       "\n",
       "          Sentiment(predict)  Difference(Phrase)  \n",
       "PhraseId                                          \n",
       "1                          1                   0  \n",
       "2                          2                   0  \n",
       "3                          2                   0  \n",
       "4                          2                   0  \n",
       "5                          2                   0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "result = train.copy()\n",
    "result[\"Sentiment(predict)\"] = y_predict\n",
    "result[\"Difference(Phrase)\"] = np.abs(y_train - y_predict)\n",
    "\n",
    "print(result.shape)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8529,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceId\n",
       "1    0.238095\n",
       "2    0.500000\n",
       "3    0.142857\n",
       "4    0.400000\n",
       "5    0.500000\n",
       "Name: Difference(Phrase), dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = result.groupby(\"SentenceId\")[\"Difference(Phrase)\"].mean()\n",
    "print(sentiment.shape)\n",
    "sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase(origin)</th>\n",
       "      <th>Sentiment(predict)</th>\n",
       "      <th>Difference(Phrase)</th>\n",
       "      <th>Difference(Sentence)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79350</th>\n",
       "      <td>4087</td>\n",
       "      <td>can not recommend it .</td>\n",
       "      <td>0</td>\n",
       "      <td>ca n't recommend it .</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79349</th>\n",
       "      <td>4087</td>\n",
       "      <td>I can not recommend it .</td>\n",
       "      <td>0</td>\n",
       "      <td>I ca n't recommend it .</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113297</th>\n",
       "      <td>6020</td>\n",
       "      <td>A real snooze .</td>\n",
       "      <td>0</td>\n",
       "      <td>A real snooze .</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113298</th>\n",
       "      <td>6020</td>\n",
       "      <td>real snooze .</td>\n",
       "      <td>0</td>\n",
       "      <td>real snooze .</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18421</th>\n",
       "      <td>807</td>\n",
       "      <td>Execrable .</td>\n",
       "      <td>0</td>\n",
       "      <td>Execrable .</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                    Phrase  Sentiment  \\\n",
       "PhraseId                                                    \n",
       "79350           4087    can not recommend it .          0   \n",
       "79349           4087  I can not recommend it .          0   \n",
       "113297          6020           A real snooze .          0   \n",
       "113298          6020             real snooze .          0   \n",
       "18421            807               Execrable .          0   \n",
       "\n",
       "                   Phrase(origin)  Sentiment(predict)  Difference(Phrase)  \\\n",
       "PhraseId                                                                    \n",
       "79350       ca n't recommend it .                   4                   4   \n",
       "79349     I ca n't recommend it .                   4                   4   \n",
       "113297            A real snooze .                   3                   3   \n",
       "113298              real snooze .                   3                   3   \n",
       "18421                 Execrable .                   2                   2   \n",
       "\n",
       "          Difference(Sentence)  \n",
       "PhraseId                        \n",
       "79350                      4.0  \n",
       "79349                      4.0  \n",
       "113297                     3.0  \n",
       "113298                     3.0  \n",
       "18421                      2.5  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_sentiment(sentence_id):\n",
    "    return sentiment.loc[sentence_id]\n",
    "\n",
    "result[\"Difference(Sentence)\"] = result[\"SentenceId\"].apply(find_sentiment)\n",
    "result = result.sort_values(by=\"Difference(Sentence)\", ascending=False)\n",
    "\n",
    "print(result.shape)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result[0:1000].to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocabulary = vectorizer.get_feature_names()\n",
    "# vocabulary[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(vocabulary, columns=[\"word\"]).to_csv(\"vocabulary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# result[result[\"Phrase\"].str.contains(\"can not recommend\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-0.7.post3.tar.gz (450kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files/directories in C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-a_t6bis_\\xgboost\\pip-egg-info (from PKG-INFO)\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\big\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "# import xgboost as xgb\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# params = {\n",
    "#     'booster': 'gblinear',\n",
    "#     'objective': 'multi:softmax',\n",
    "#     'eval_metric': 'merror',\n",
    "#     'lambda': 2.186753e-03,\n",
    "#     'alpha': 1.286904,\n",
    "#     'lambda_bias': 6.191707e+00,\n",
    "#     'num_class': 5,\n",
    "#     'nthread': 8,\n",
    "#     'silent': 1,\n",
    "# }\n",
    "\n",
    "# %time booster = xgb.train(params, dtrain, num_boost_round=98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-9e80ed8b4bde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\big\\Anaconda3\\envs\\py36\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\big\\Anaconda3\\envs\\py36\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dtest = xgb.DMatrix(X_test.toarray())\n",
    "\n",
    "# predictions = booster.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=6.762746e-06, average=False, class_weight=None,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=37, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66292x79810 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8399571 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 3, 3, 3, 2, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions = model.predict(X_test)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(predictions.shape)\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentiment\n",
       "PhraseId           \n",
       "156061            3\n",
       "156062            3\n",
       "156063            2\n",
       "156064            3\n",
       "156065            3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"data/sampleSubmission.csv\", index_col=\"PhraseId\")\n",
    "\n",
    "submission[\"Sentiment\"] = predictions\n",
    "\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"data/sampleSubmission.csv\", index_col=\"PhraseId\")\n",
    "\n",
    "submission[\"Sentiment\"] = predictions.astype('int')\n",
    "\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 경로(ex: baseline-script.csv)는 사용자 설정마다 다름\n",
    "#submission.to_csv(\"use-xgboost.csv\")\n",
    "# 경로(ex: baseline-script.csv)는 사용자 설정마다 다름\n",
    "filename = \"use-xgboost_{score}.csv\".format(score=\"{0:.5f}\".format(score))\n",
    "submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
