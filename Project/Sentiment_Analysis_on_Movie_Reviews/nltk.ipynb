{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "5                 2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"input/train.tsv\", sep=\"\\t\", index_col=\"PhraseId\")\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Stemmer \n",
    "문법의 특징으로부터 데이터를 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.stem.snowball.SnowballStemmer at 0x1a0c07b9b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KoNLPy (한국어에서 사용 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'food'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('foods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recommend'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('recommended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'studi'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('studied') \n",
    "# stemmer는 단어의 어근 형태로 변형한다. (studi로 변형된 것으로 알 수 있음)\n",
    "# 과거형이 중요한 정보를 가질 때는 stemmer를 쓰면 안된다 (그런 경우가 있나보다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Highly recommended viewing for its courage , ideas , technical proficiency and great acting .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phrase = train.loc[2274][\"Phrase\"]\n",
    "Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly high\n",
      "recommended recommend\n",
      "viewing view\n",
      "for for\n",
      "its it\n",
      "courage courag\n",
      ", ,\n",
      "ideas idea\n",
      ", ,\n",
      "technical technic\n",
      "proficiency profici\n",
      "and and\n",
      "great great\n",
      "acting act\n",
      ". .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'high recommend view for it courag , idea , technic profici and great act .'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Phrase.split(\" \")\n",
    "\n",
    "stemmed_words = []\n",
    "for word in words:\n",
    "    stemmed_word = stemmer.stem(word)\n",
    "    stemmed_words.append(stemmed_word)\n",
    "    print(word, stemmed_word)\n",
    "    \n",
    "stemmed_phrase = \" \".join(stemmed_words)\n",
    "stemmed_phrase\n",
    "\n",
    "# 아래와 같이 표현이 가능하다 (for문 줄이기)\n",
    "words = Phrase.split(\" \")\n",
    "stemmed_words = [stemmer.stem(w) for w in words]\n",
    "stemmed_phrase = \" \".join(stemmed_words)\n",
    "stemmed_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/user/anaconda3/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stemming...: 100%|██████████| 156060/156060 [00:16<00:00, 9496.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase(Stemmed)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>a seri of escapad demonstr the adag that what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>a seri of escapad demonstr the adag that what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>a seri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>seri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment                                    Phrase(Stemmed)  \n",
       "PhraseId                                                                \n",
       "1                 1  a seri of escapad demonstr the adag that what ...  \n",
       "2                 2  a seri of escapad demonstr the adag that what ...  \n",
       "3                 2                                             a seri  \n",
       "4                 2                                                  a  \n",
       "5                 2                                               seri  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 함수화하여 쉽게 사용하기\n",
    "\n",
    "\n",
    "def stem_phrase(phrase): \n",
    "    words = phrase.split(\" \")\n",
    "    stemmed_words = [stemmer.stem(w) for w in words]\n",
    "    stemmed_phrase = \" \".join(stemmed_words)\n",
    "\n",
    "    return stemmed_phrase\n",
    "\n",
    "tqdm.pandas(desc=\"stemming...\")\n",
    "train[\"Phrase(Stemmed)\"] = train[\"Phrase\"].progress_apply(stem_phrase)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId\n",
       "1         A series of escapades demonstrating the adage ...\n",
       "2         A series of escapades demonstrating the adage ...\n",
       "3                                                  A series\n",
       "4                                                         A\n",
       "5                                                    series\n",
       "6         of escapades demonstrating the adage that what...\n",
       "7                                                        of\n",
       "8         escapades demonstrating the adage that what is...\n",
       "9                                                 escapades\n",
       "10        demonstrating the adage that what is good for ...\n",
       "11                                  demonstrating the adage\n",
       "12                                            demonstrating\n",
       "13                                                the adage\n",
       "14                                                      the\n",
       "15                                                    adage\n",
       "16                          that what is good for the goose\n",
       "17                                                     that\n",
       "18                               what is good for the goose\n",
       "19                                                     what\n",
       "20                                    is good for the goose\n",
       "21                                                       is\n",
       "22                                       good for the goose\n",
       "23                                                     good\n",
       "24                                            for the goose\n",
       "25                                                      for\n",
       "26                                                the goose\n",
       "27                                                    goose\n",
       "28        is also good for the gander , some of which oc...\n",
       "29        is also good for the gander , some of which oc...\n",
       "30                                                  is also\n",
       "                                ...                        \n",
       "156031                          a joke in the United States\n",
       "156032    The movie 's downfall is to substitute plot fo...\n",
       "156033                                The movie 's downfall\n",
       "156034              is to substitute plot for personality .\n",
       "156035                is to substitute plot for personality\n",
       "156036                   to substitute plot for personality\n",
       "156037                      substitute plot for personality\n",
       "156038                                      substitute plot\n",
       "156039                                      for personality\n",
       "156040    The film is darkly atmospheric , with Herrmann...\n",
       "156041    is darkly atmospheric , with Herrmann quietly ...\n",
       "156042    is darkly atmospheric , with Herrmann quietly ...\n",
       "156043                              is darkly atmospheric ,\n",
       "156044                                is darkly atmospheric\n",
       "156045    with Herrmann quietly suggesting the sadness a...\n",
       "156046    Herrmann quietly suggesting the sadness and ob...\n",
       "156047                                             Herrmann\n",
       "156048    quietly suggesting the sadness and obsession b...\n",
       "156049    suggesting the sadness and obsession beneath H...\n",
       "156050                 suggesting the sadness and obsession\n",
       "156051                            the sadness and obsession\n",
       "156052                                sadness and obsession\n",
       "156053                                          sadness and\n",
       "156054          beneath Hearst 's forced avuncular chortles\n",
       "156055                  Hearst 's forced avuncular chortles\n",
       "156056                                            Hearst 's\n",
       "156057                            forced avuncular chortles\n",
       "156058                                   avuncular chortles\n",
       "156059                                            avuncular\n",
       "156060                                             chortles\n",
       "Name: Phrase, Length: 156060, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId\n",
       "1         high recommend view for it courag , idea , tec...\n",
       "2         high recommend view for it courag , idea , tec...\n",
       "3         high recommend view for it courag , idea , tec...\n",
       "4         high recommend view for it courag , idea , tec...\n",
       "5         high recommend view for it courag , idea , tec...\n",
       "6         high recommend view for it courag , idea , tec...\n",
       "7         high recommend view for it courag , idea , tec...\n",
       "8         high recommend view for it courag , idea , tec...\n",
       "9         high recommend view for it courag , idea , tec...\n",
       "10        high recommend view for it courag , idea , tec...\n",
       "11        high recommend view for it courag , idea , tec...\n",
       "12        high recommend view for it courag , idea , tec...\n",
       "13        high recommend view for it courag , idea , tec...\n",
       "14        high recommend view for it courag , idea , tec...\n",
       "15        high recommend view for it courag , idea , tec...\n",
       "16        high recommend view for it courag , idea , tec...\n",
       "17        high recommend view for it courag , idea , tec...\n",
       "18        high recommend view for it courag , idea , tec...\n",
       "19        high recommend view for it courag , idea , tec...\n",
       "20        high recommend view for it courag , idea , tec...\n",
       "21        high recommend view for it courag , idea , tec...\n",
       "22        high recommend view for it courag , idea , tec...\n",
       "23        high recommend view for it courag , idea , tec...\n",
       "24        high recommend view for it courag , idea , tec...\n",
       "25        high recommend view for it courag , idea , tec...\n",
       "26        high recommend view for it courag , idea , tec...\n",
       "27        high recommend view for it courag , idea , tec...\n",
       "28        high recommend view for it courag , idea , tec...\n",
       "29        high recommend view for it courag , idea , tec...\n",
       "30        high recommend view for it courag , idea , tec...\n",
       "                                ...                        \n",
       "156031    high recommend view for it courag , idea , tec...\n",
       "156032    high recommend view for it courag , idea , tec...\n",
       "156033    high recommend view for it courag , idea , tec...\n",
       "156034    high recommend view for it courag , idea , tec...\n",
       "156035    high recommend view for it courag , idea , tec...\n",
       "156036    high recommend view for it courag , idea , tec...\n",
       "156037    high recommend view for it courag , idea , tec...\n",
       "156038    high recommend view for it courag , idea , tec...\n",
       "156039    high recommend view for it courag , idea , tec...\n",
       "156040    high recommend view for it courag , idea , tec...\n",
       "156041    high recommend view for it courag , idea , tec...\n",
       "156042    high recommend view for it courag , idea , tec...\n",
       "156043    high recommend view for it courag , idea , tec...\n",
       "156044    high recommend view for it courag , idea , tec...\n",
       "156045    high recommend view for it courag , idea , tec...\n",
       "156046    high recommend view for it courag , idea , tec...\n",
       "156047    high recommend view for it courag , idea , tec...\n",
       "156048    high recommend view for it courag , idea , tec...\n",
       "156049    high recommend view for it courag , idea , tec...\n",
       "156050    high recommend view for it courag , idea , tec...\n",
       "156051    high recommend view for it courag , idea , tec...\n",
       "156052    high recommend view for it courag , idea , tec...\n",
       "156053    high recommend view for it courag , idea , tec...\n",
       "156054    high recommend view for it courag , idea , tec...\n",
       "156055    high recommend view for it courag , idea , tec...\n",
       "156056    high recommend view for it courag , idea , tec...\n",
       "156057    high recommend view for it courag , idea , tec...\n",
       "156058    high recommend view for it courag , idea , tec...\n",
       "156059    high recommend view for it courag , idea , tec...\n",
       "156060    high recommend view for it courag , idea , tec...\n",
       "Name: Phrase, Length: 156060, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Phrase\"].apply(stem_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizer\n",
    "결과가 단어로 나온다. (어근X) \n",
    "데이터 분석적으로 판단한다. (2개 중 하나만 쓰기도하고 둘다 쓰기도한다) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordNetLemmatizer>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.nltk.org/api/nltk.stem.html\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('feet', 'foot')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('feet'), lemmatizer.lemmatize('feet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('studi', 'study')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('studies'), lemmatizer.lemmatize('studies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('went', 'went')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('went'), lemmatizer.lemmatize('went')\n",
    "#lemmatizer는 단어가 동사인지 명사인지에 따라 결과가 달라진다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('went', 'go')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos === part of speech\n",
    "stemmer.stem('went'), lemmatizer.lemmatize('went', pos='v') # 동사로 할 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pos Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function nltk.tokenize.word_tokenize>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "phrase = train.loc[2274][\"Phrase\"]\n",
    "phrase\n",
    "\n",
    "word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Highly',\n",
       " 'recommended',\n",
       " 'viewing',\n",
       " 'for',\n",
       " 'its',\n",
       " 'courage',\n",
       " ',',\n",
       " 'ideas',\n",
       " ',',\n",
       " 'technical',\n",
       " 'proficiency',\n",
       " 'and',\n",
       " 'great',\n",
       " 'acting',\n",
       " '.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the_DT', 'door_NN', 'is_VBZ', 'already_RB', 'closed_VBN']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used\n",
    "words_pos = pos_tag(word_tokenize(phrase))\n",
    "words_pos\n",
    "\n",
    "[\"_\".join(w) for w in words_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you_PRP', 'should_MD', 'close_VBD', 'the_DT', 'door_NN']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# close를 비교해보면 문맥에 따라 동사인지 명사인지 구분이 가능하다\n",
    "# 이럴 때는 close_VB, close_RB와 같이 하나의 단어로 만들어 count하는 방법도 있다\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "phrase = \"you should closed the door\"\n",
    "words = phrase.split(\" \")\n",
    "\n",
    "stemmed_words = [stemmer.stem(w) for w in words]\n",
    "stemmed_phrase = \" \".join(stemmed_words)\n",
    "\n",
    "ok = pos_tag(word_tokenize(phrase))\n",
    "test = [[o[0], o[1]] for o in ok]\n",
    "test = [\"_\".join([stemmer.stem(o[0]), o[1]]) for o in ok]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_D door_N is_V alreadi_R close_V\n",
      "the_D door_N is_V alreadi_V close_R\n"
     ]
    }
   ],
   "source": [
    "phrase = \"the door is already closed\"\n",
    "words = phrase.split(\" \")\n",
    "\n",
    "stemmed_words = [stemmer.stem(w) for w in words]\n",
    "stemmed_phrase = \" \".join(stemmed_words)\n",
    "\n",
    "def distributionPoS(tag):\n",
    "    return tag[0]\n",
    "\n",
    "def post_tag_lemm_v_or_n_phrase(phrase): \n",
    "    words = word_tokenize(phrase)\n",
    "    pos_tag_split_words = pos_tag(words)\n",
    "    pos_tag_words = [\"_\".join([lemmatizer.lemmatize(o[0]), distributionPoS(o[1])]) for o in pos_tag_split_words]\n",
    "    pos_tag_words = \" \".join(pos_tag_words)\n",
    "\n",
    "    return pos_tag_words\n",
    "\n",
    "def post_tag_lemm_stem_phrase(phrase): \n",
    "    words = word_tokenize(phrase)\n",
    "    pos_tag_split_words = pos_tag(words)\n",
    "    pos_tag_words = [\"_\".join([stemmer.stem(lemmatizer.lemmatize(o[0])), distributionPoS(o[1])]) for o in pos_tag_split_words]\n",
    "    pos_tag_words = \" \".join(pos_tag_words)\n",
    "\n",
    "    return pos_tag_words\n",
    "\n",
    "print(post_tag_lemm_stem_phrase(phrase))\n",
    "print(post_tag_lemm_v_or_n_phrase(stemmed_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the_DT'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"A23\"\n",
    "\n",
    "test[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
